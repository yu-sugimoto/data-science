{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 前処理"
      ],
      "metadata": {
        "id": "1Dw0n-y1FEAI"
      },
      "id": "1Dw0n-y1FEAI"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c3777aad",
      "metadata": {
        "id": "c3777aad",
        "outputId": "64d4165c-df5b-4af8-8c0f-bebf1c04661e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Porchのインストール\n",
        "import torch\n",
        "\n",
        "# cudaが使えるなら使用\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b4329431",
      "metadata": {
        "id": "b4329431"
      },
      "outputs": [],
      "source": [
        "# 学習データ（例）\n",
        "sample_texts = [\n",
        "    \"Hello, how are you doing today?\",\n",
        "    \"Hello, how are you?\",\n",
        "    \"Hello, how are you?\",\n",
        "    \"How are you doing?\",\n",
        "    \"This is a small example dataset for BERT.\",\n",
        "    \"We will train a mini BERT model to learn masked language modeling.\",\n",
        "    \"Large models usually require huge datasets and computational resources.\",\n",
        "    \"But here, we will just use a small corpus.\",\n",
        "    \"Hello, how are you doing again today?\",\n",
        "    \"Hello, how are you doing once more?\",\n",
        "\t  \"Hello, how are you doing?\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "423605aa",
      "metadata": {
        "id": "423605aa",
        "outputId": "88edd994-2230-4dbe-d6d6-419e463e9bbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Hello', 'how', 'are', 'you', 'doing', 'today'],\n",
              " ['Hello', 'how', 'are', 'you'],\n",
              " ['Hello', 'how', 'are', 'you'],\n",
              " ['How', 'are', 'you', 'doing'],\n",
              " ['This', 'is', 'a', 'small', 'example', 'dataset', 'for', 'BERT'],\n",
              " ['We',\n",
              "  'will',\n",
              "  'train',\n",
              "  'a',\n",
              "  'mini',\n",
              "  'BERT',\n",
              "  'model',\n",
              "  'to',\n",
              "  'learn',\n",
              "  'masked',\n",
              "  'language',\n",
              "  'modeling'],\n",
              " ['Large',\n",
              "  'models',\n",
              "  'usually',\n",
              "  'require',\n",
              "  'huge',\n",
              "  'datasets',\n",
              "  'and',\n",
              "  'computational',\n",
              "  'resources'],\n",
              " ['But', 'here', 'we', 'will', 'just', 'use', 'a', 'small', 'corpus'],\n",
              " ['Hello', 'how', 'are', 'you', 'doing', 'again', 'today'],\n",
              " ['Hello', 'how', 'are', 'you', 'doing', 'once', 'more'],\n",
              " ['Hello', 'how', 'are', 'you', 'doing']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "def simple_tokenize(sentence):\n",
        "\t  # 文の中の句読点を削除\n",
        "    for p in [\".\", \",\", \"?\", \"!\", \":\", \";\"]:\n",
        "        sentence = sentence.replace(p, \"\")\n",
        "  \t# 文をスペースで分割してトークン化\n",
        "    tokens = sentence.strip().split()\n",
        "    return tokens\n",
        "\n",
        "# sample_textsの各文にsimple_tokenize関数を適用\n",
        "# 結果は、各文のトークンを保持するリストのリスト\n",
        "tokenized_texts = [simple_tokenize(t) for t in sample_texts] # 内包表記\n",
        "tokenized_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zcD8ikrREQ4z"
      },
      "id": "zcD8ikrREQ4z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 辞書の作成"
      ],
      "metadata": {
        "id": "TrsX-qWWESW7"
      },
      "id": "TrsX-qWWESW7"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eb5a7c8a",
      "metadata": {
        "id": "eb5a7c8a"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# 全てのトークンを保存\n",
        "all_tokens = []\n",
        "for tokens in tokenized_texts:\n",
        "    all_tokens.extend(tokens)\n",
        "\n",
        "# それぞれのトークンの出現回数をカウント\n",
        "# Counterでユニークな数をカウント\n",
        "counts = Counter(all_tokens)\n",
        "\n",
        "# 特殊トークンを定義\n",
        "# [PAD]はシーケンスの長さを揃えるために使用\n",
        "# [UNK]は語彙にない未知のトークン用\n",
        "# [CLS]は文の開始を示すために使用\n",
        "# [SEP]は文の終了を示すために使用\n",
        "# [MASK]はMLM用\n",
        "# その後、通常のトークンをアルファベット順にソートして追加\n",
        "vocab = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"] + sorted(counts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2つの辞書を作成\n",
        "# word2idx: トークン文字列 -> 整数インデックス\n",
        "# idx2word: 整数インデックス -> トークン文字列\n",
        "word2idx = {w: i for i, w in enumerate(vocab)} # 内包表記で辞書を作成\n",
        "idx2word = {i: w for w, i in word2idx.items()} # 数値化されたトークンを元に戻すことが可能\n",
        "\n",
        "# vocab_sizeは、特殊トークンを含むユニークなトークンの数\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocab size: {vocab_size}\")"
      ],
      "metadata": {
        "id": "2jWAxFDTFfR_",
        "outputId": "36e80cee-b24a-463f-8869-b22919bf2bbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2jWAxFDTFfR_",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "323d1b0c",
      "metadata": {
        "id": "323d1b0c"
      },
      "outputs": [],
      "source": [
        "# トークンのリストを整数IDのリストに変換\n",
        "# - [CLS]を先頭に、[SEP]を末尾に追加\n",
        "# - 各トークンを整数IDに変換\n",
        "# - max_lenに合わせて[PAD]でパディングまたはトランケート\n",
        "def encode(tokens, word2idx, max_len=12): # 有効なトークンを作成する関数\n",
        "\n",
        "  \t# [CLS]は文の開始を示し、[SEP]は文の終了を示す\n",
        "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "\n",
        "  \t# word2idx辞書を使ってトークンを整数IDに変換\n",
        "    token_ids = []\n",
        "    for t in tokens:\n",
        "\t    \t# トークンが語彙にない場合は[UNK]を使用\n",
        "        token_ids.append(word2idx.get(t, word2idx[\"[UNK]\"])) # word2idx[\"[UNK]\"]：unknownのトークンを設定する引数\n",
        "\n",
        "\t  # もしtoken_idsがmax_lenより短い場合、[PAD]を追加してシーケンスを埋める\n",
        "    if len(token_ids) < max_len:\n",
        "        token_ids += [word2idx[\"[PAD]\"]] * (max_len - len(token_ids)) # パッティングで足りない部分だけ埋める\n",
        "    else:\n",
        "\t    \t# 長すぎる場合はmax_lenに合わせてトランケート\n",
        "        token_ids = token_ids[:max_len] # 無理やり区切る\n",
        "    return token_ids"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# トークン化された各文をencode関数を使ってエンコードし、encoded_datasetsに保存\n",
        "encoded_datasets = []\n",
        "for tokens in tokenized_texts:\n",
        "    encoded_datasets.append(encode(tokens, word2idx, max_len=12))\n",
        "print(encoded_datasets)"
      ],
      "metadata": {
        "id": "gCcx5KyZG8pt",
        "outputId": "9a46b1ab-1cf7-4dd8-8cf0-71cc0d631c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gCcx5KyZG8pt",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 7, 24, 15, 47, 20, 41, 3, 0, 0, 0, 0], [2, 7, 24, 15, 47, 3, 0, 0, 0, 0, 0, 0], [2, 7, 24, 15, 47, 3, 0, 0, 0, 0, 0, 0], [2, 8, 15, 47, 20, 3, 0, 0, 0, 0, 0, 0], [2, 10, 26, 12, 39, 21, 18, 22, 5, 3, 0, 0], [2, 11, 46, 42, 12, 31, 5, 32, 40, 29, 30, 28], [2, 9, 34, 44, 37, 25, 19, 14, 16, 38, 3, 0], [2, 6, 23, 45, 46, 27, 43, 12, 39, 17, 3, 0], [2, 7, 24, 15, 47, 20, 13, 41, 3, 0, 0, 0], [2, 7, 24, 15, 47, 20, 36, 35, 3, 0, 0, 0], [2, 7, 24, 15, 47, 20, 3, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorchのテンソルに変換\n",
        "encoded_datasets = torch.tensor(encoded_datasets)\n",
        "encoded_datasets.shape # [文の数, max_len]"
      ],
      "metadata": {
        "id": "TXDPMt2FHgva",
        "outputId": "7531e96b-a676-41fb-fd8f-916e7c1ca2d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TXDPMt2FHgva",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "45d33bd0",
      "metadata": {
        "id": "45d33bd0"
      },
      "outputs": [],
      "source": [
        "# マスク関数を定義\n",
        "# MLMのためにトークンをランダムに[MASK]で置き換える\n",
        "# ただし、[PAD]、[CLS]、[SEP]、[MASK]などの特殊トークンはスキップする\n",
        "def mask_tokens(batch, mask_prob=0.15):\n",
        "    # バッチは2次元テンソルで、形状は(batch_size, sequence_length)\n",
        "    # 元のデータをそのまま変更しないようにクローンする\n",
        "    input_ids = batch.clone()\n",
        "\n",
        "    # labelsは同じ形状のテンソルで、-100で埋める\n",
        "    # CrossEntropyLossでignore_index=-100を指定すると、損失計算時に無視できる\n",
        "    # マスクの部分だけEntropyLossで計算させたい\n",
        "    labels = torch.full_like(batch, -100)\n",
        "\n",
        "\t  # 特殊トークンのIDを定義し、マスクしないようにする\n",
        "    special_ids = {\n",
        "        word2idx[\"[PAD]\"],\n",
        "        word2idx[\"[CLS]\"],\n",
        "        word2idx[\"[SEP]\"],\n",
        "        word2idx[\"[MASK]\"]\n",
        "    }\n",
        "\n",
        "\t  # バッチの各シーケンスとトークン位置をループして、マスクするかどうかを決定する　※今回は0～11まで回す\n",
        "    for i in range(batch.size(0)):       # バッチ\n",
        "        for j in range(batch.size(1)):   # トークン位置\n",
        "\n",
        "\t\t\t      # トークンIDを取得\n",
        "            token_id = batch[i, j].item()\n",
        "\n",
        "\t      \t\t# 特殊トークンの場合はスキップ\n",
        "            if token_id in special_ids:\n",
        "                continue\n",
        "\n",
        "\t      \t\t# 15%の確率でそのトークンを[MASK]に置き換える\n",
        "            if random.random() < mask_prob:\n",
        "                input_ids[i, j] = word2idx[\"[MASK]\"]\n",
        "\t\t          \t# 置き換えた場所の正解ラベルを保持（それ以外は-100で損失計算時に無視される）\n",
        "                labels[i, j] = token_id\n",
        "\n",
        "\t  # マスクされたトークンのIDと正解ラベルを返す\n",
        "    return input_ids, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERTの実装"
      ],
      "metadata": {
        "id": "86bPNqgCJIy1"
      },
      "id": "86bPNqgCJIy1"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2f2ecf47",
      "metadata": {
        "id": "2f2ecf47"
      },
      "outputs": [],
      "source": [
        "# BERT：特徴量の抽出に特化しているのでencoderしか使っていないモデル\n",
        "# BERT用のMultiHeadSelfAttentionクラスを定義\n",
        "\n",
        "# 1. MultiHeadSelfAttention: Transformerで使われる自己注意機構\n",
        "# 2. TransformerEncoderBlock: 自己注意機構とフィードフォワードネットワークを組み合わせたブロック\n",
        "# 3. PositionalEncoding: トークンの位置情報を加えるためのサイン波とコサイン波を使ったエンコーディング\n",
        "# 4. MiniBert: 複数のエンコーダーブロックを積み重ねた小型モデル\n",
        "\n",
        "# (A) MultiHeadSelfAttention\n",
        "# このレイヤーは、文中の各トークンが他のトークンにどれだけ「注意」を払うべきかを計算する。\n",
        "# 重要な関係に焦点を当てます。複数の「ヘッド」を使うことで、各ヘッドが異なる関係パターンを学習できる\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads): # headの数が多いほど学習できる\n",
        "        super().__init__()\n",
        "\n",
        "\t    \t# 入力の埋め込みの次元数\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "\t    \t# アテンションヘッドの数\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "\t    \t# それぞれのヘッドの埋め込みの次元数は、入力の埋め込み次元をnum_headsで割った数\n",
        "        self.head_dim = embed_dim // num_heads # headが増えても計算量は増えないように\n",
        "\n",
        "\t    \t# クエリ、キー、バリューにそれぞれ重みがあるため、3つの線形変換を定義\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    \t\t# 出力の重みがあるため、最終的な線形変換を定義\n",
        "        self.out = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\t    \t# Bはバッチサイズ、Sはシーケンスの長さ、Eは埋め込みの次元数\n",
        "        B, S, E = x.size() # B: batch(64), S: squence(12), E: embedding(768)\n",
        "\n",
        "\t\t    # セルフアテンションのため、クエリ、キー、バリューは同じ入力 [B, S, E] -> [B, S, E]\n",
        "        Q = self.query(x)\n",
        "        K = self.key(x)\n",
        "        V = self.value(x)\n",
        "\n",
        "\t\t    # マルチヘッドアテンション用にテンソルの形状を変える [B, S, E] -> [B, num_heads, S, head_dim]\n",
        "        Q = Q.view(B, S, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K = K.view(B, S, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V = V.view(B, S, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Kの転地を取り、Qと掛け算することで、各トークンが他のトークンにどれだけ注意を払うべきかを計算\n",
        "        # そして、head_dimの平方根でスケーリングすることで、数値の安定性を保つ\n",
        "        # [B, num_heads, S, head_dim] * [B, num_heads, head_dim, S] -> [B, num_heads, S, S]\n",
        "        # 論文で示された式(https://arxiv.org/abs/1706.03762)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
        "\n",
        "\t    \t# Softmaxを使って、スコアを確率に変換\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "\t    \t# 確率をバリューに掛け算することで、各トークンの重要度を考慮したコンテキストを得る\n",
        "        context = torch.matmul(attn_weights, V)\n",
        "\n",
        "        # Now, context is still in a multi-head form. We reorder it back to (B, S, E).\n",
        "\t\t    # コンテキストは[B, num_heads, S, head_dim]の形をしている\n",
        "\t    \t# 最初に転地をし[B, S, num_heads, head_dim]にし、次に連結して[B, S, E]の形にする\n",
        "        context = context.transpose(1, 2).contiguous().view(B, S, E)\n",
        "\n",
        "\t    \t# 最終的な線形変換を通して、全てのヘッドからの情報を統合する\n",
        "        out = self.out(context)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "79466dad",
      "metadata": {
        "id": "79466dad"
      },
      "outputs": [],
      "source": [
        "# TransformerEncoderBlock\n",
        "# Transformerエンコーダーの1層。マルチヘッドアテンション、次にフィードフォワードサブレイヤーがあり、\n",
        "# 各サブレイヤーの周りに残差接続と正規化がある。\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "\t    \t# トークン間の関係を学習するためのマルチヘッドアテンション\n",
        "        self.attn = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "\n",
        "\t    \t# 各トークンの埋め込みを正規化することで、トレーニングを安定させるレイヤー正規化層\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "\t    \t# 2つの線形変換を使ったフィードフォワードネットワーク\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "\t\t    # フィードフォワードネットワークの出力を正規化するためのレイヤー正規化層\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "\t      # 過学習を防ぐために、アクティベーションの一部をランダムにゼロにするドロップアウト\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # セルフアテンションを通して、トークン間の関係を学習（単語同士の関係性）\n",
        "        # [B, S, E] -> [B, S, E]\n",
        "        attn_out = self.attn(x)\n",
        "\n",
        "        # ドロップアウトを適用し、残渣接続を追加して、レイヤー正規化を行う\n",
        "        # [B, S, E] + [B, S, E] -> [B, S, E]\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "\n",
        "        # フィードフォワードネットワークを通して、各トークンの埋め込みを変換\n",
        "        # [B, S, E] -> [B, S, E]\n",
        "        ff_out = self.ff(x)\n",
        "\n",
        "\t\t    # もう一度ドロップアウトを適用し、残渣接続を追加して、レイヤー正規化を行う\n",
        "        x = self.norm2(x + self.dropout(ff_out))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1c236d55",
      "metadata": {
        "id": "1c236d55"
      },
      "outputs": [],
      "source": [
        "# 位置エンコーディング\n",
        "# トランスフォーマーは、シーケンス内の各トークンの位置を本質的に知らないため、\n",
        "# 各トークンの位置に関する情報を注入する「位置エンコーディング」を追加。\n",
        "# サイン波とコサイン波を使って、異なる周波数で位置をエンコードする。\n",
        "\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_len=1000):\n",
        "        super().__init__()\n",
        "\t\t    # 位置エンコーディングを保存するためのテンソルを作成\n",
        "        pe = torch.zeros(max_len, embed_dim)\n",
        "\n",
        "        # 各トークンの位置[0, 1, 2, ..., max_len-1]を作成し\n",
        "        # [max_len, 1]\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "\t    \t# 周波数を設定するために使用するdiv_termを作成\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * -(math.log(10000.0) / embed_dim))\n",
        "\n",
        "\t    \t# 偶数はサイン波、奇数はコサイン波を使用して位置をエンコード\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # register_bufferは、peが学習パラメータではなく、このモジュールに属し、\n",
        "        # モデルと一緒にGPUに移動されることを保証するために使用\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "\t    \t# xの形状は(B, S, E)で、最初のS位置に位置エンコーディングを追加\n",
        "        seq_len = x.size(1)\n",
        "        x = x + self.pe[:, :seq_len, :]\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8e17cf25",
      "metadata": {
        "id": "8e17cf25"
      },
      "outputs": [],
      "source": [
        "# MiniBERT\n",
        "# - トークンIDを埋め込むためのEmbeddingレイヤー\n",
        "# - 位置情報を加えるためのPositionalEncoding\n",
        "# - 複数のTransformerEncoderBlockを積み重ねたもの\n",
        "# - 各トークン位置に対して語彙のロジットを出力する最終的な線形レイヤー(mlm_head)\n",
        "\n",
        "class MiniBert(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embed_dim=64,   # それぞれのトークンの埋め込みの次元数\n",
        "        num_heads=2,    # マルチヘッドセルフアテンションで使用するヘッドの数\n",
        "        ff_dim=128,     # それぞれのエンコーダーブロックのフィードフォワード層の次元数\n",
        "        num_layers=2,   # TransformerEncoderBlockの数\n",
        "        max_len=12      # 位置埋め込みの最大長\n",
        "    ):\n",
        "        super().__init__()\n",
        "\t\t    # 「意味」や「特徴」を捉えるために各トークンをベクトルに変換\n",
        "        self.token_embed = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "    \t\t# トークンの位置情報を加えるための位置エンコーディングモジュール\n",
        "        self.pos_encoding = PositionalEncoding(embed_dim, max_len)\n",
        "\n",
        "\t    \t# TransformerEncoderBlockのリスト\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerEncoderBlock(embed_dim, num_heads, ff_dim)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        # The final linear layer for Masked Language Modeling: we predict the correct token out of vocab_size.\n",
        "\n",
        "        # MLM用の最終的な線形レイヤー\n",
        "        # 出力は辞書（vocabulary）のサイズに等しいロジット\n",
        "        self.mlm_head = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # トークンIDを埋め込みベクトルに変換\n",
        "        # [B, S] -> [B, S, E]\n",
        "        x = self.token_embed(x)\n",
        "\n",
        "        # 位置エンコーディングを追加\n",
        "        # [B, S, E] -> [B, S, E]\n",
        "        x = self.pos_encoding(x)\n",
        "\n",
        "\t    \t# それぞれのエンコーダーブロックを順番に通す\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "    \t\t# 最終的な線形レイヤーを通して、各トークン位置に対して語彙のロジットを出力\n",
        "        logits = self.mlm_head(x)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5af9ba23",
      "metadata": {
        "id": "5af9ba23",
        "outputId": "0dd75a98-2b20-459c-b892-4c36876ff538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] - Loss: 24.4430\n",
            "Epoch [2/100] - Loss: 23.0113\n",
            "Epoch [3/100] - Loss: 21.6758\n",
            "Epoch [4/100] - Loss: 20.3355\n",
            "Epoch [5/100] - Loss: 21.2654\n",
            "Epoch [6/100] - Loss: 21.5591\n",
            "Epoch [7/100] - Loss: 21.2449\n",
            "Epoch [8/100] - Loss: 17.3930\n",
            "Epoch [9/100] - Loss: 21.8566\n",
            "Epoch [10/100] - Loss: 21.5743\n",
            "Epoch [11/100] - Loss: 21.5716\n",
            "Epoch [12/100] - Loss: 19.3741\n",
            "Epoch [13/100] - Loss: 19.9088\n",
            "Epoch [14/100] - Loss: 18.2894\n",
            "Epoch [15/100] - Loss: 21.1580\n",
            "Epoch [16/100] - Loss: 21.2595\n",
            "Epoch [17/100] - Loss: 23.4001\n",
            "Epoch [18/100] - Loss: 17.8794\n",
            "Epoch [19/100] - Loss: 19.8632\n",
            "Epoch [20/100] - Loss: 19.3636\n",
            "Epoch [21/100] - Loss: 19.0176\n",
            "Epoch [22/100] - Loss: 18.9165\n",
            "Epoch [23/100] - Loss: 20.1735\n",
            "Epoch [24/100] - Loss: 21.3435\n",
            "Epoch [25/100] - Loss: 18.6188\n",
            "Epoch [26/100] - Loss: 19.0118\n",
            "Epoch [27/100] - Loss: 20.5975\n",
            "Epoch [28/100] - Loss: 18.8136\n",
            "Epoch [29/100] - Loss: 21.0913\n",
            "Epoch [30/100] - Loss: 21.6735\n",
            "Epoch [31/100] - Loss: 17.6368\n",
            "Epoch [32/100] - Loss: 20.5881\n",
            "Epoch [33/100] - Loss: 15.9303\n",
            "Epoch [34/100] - Loss: 16.8994\n",
            "Epoch [35/100] - Loss: 17.1131\n",
            "Epoch [36/100] - Loss: 17.6159\n",
            "Epoch [37/100] - Loss: 20.5256\n",
            "Epoch [38/100] - Loss: 17.6607\n",
            "Epoch [39/100] - Loss: 13.8518\n",
            "Epoch [40/100] - Loss: 17.6471\n",
            "Epoch [41/100] - Loss: 16.1069\n",
            "Epoch [42/100] - Loss: 20.2194\n",
            "Epoch [43/100] - Loss: 16.0968\n",
            "Epoch [44/100] - Loss: 16.4108\n",
            "Epoch [45/100] - Loss: 17.1074\n",
            "Epoch [46/100] - Loss: 18.3563\n",
            "Epoch [47/100] - Loss: 15.7431\n",
            "Epoch [48/100] - Loss: 18.6309\n",
            "Epoch [49/100] - Loss: 14.6280\n",
            "Epoch [50/100] - Loss: 14.5651\n",
            "Epoch [51/100] - Loss: 14.9606\n",
            "Epoch [52/100] - Loss: 13.9756\n",
            "Epoch [53/100] - Loss: 9.3818\n",
            "Epoch [54/100] - Loss: 16.2732\n",
            "Epoch [55/100] - Loss: 15.8270\n",
            "Epoch [56/100] - Loss: 16.9971\n",
            "Epoch [57/100] - Loss: 13.4962\n",
            "Epoch [58/100] - Loss: 16.6243\n",
            "Epoch [59/100] - Loss: 12.3191\n",
            "Epoch [60/100] - Loss: 13.9409\n",
            "Epoch [61/100] - Loss: 13.1213\n",
            "Epoch [62/100] - Loss: 14.6511\n",
            "Epoch [63/100] - Loss: 14.7186\n",
            "Epoch [64/100] - Loss: 14.8528\n",
            "Epoch [65/100] - Loss: 12.7420\n",
            "Epoch [66/100] - Loss: 16.0974\n",
            "Epoch [67/100] - Loss: 13.6367\n",
            "Epoch [68/100] - Loss: 16.1363\n",
            "Epoch [69/100] - Loss: 13.8280\n",
            "Epoch [70/100] - Loss: 11.0509\n",
            "Epoch [71/100] - Loss: 13.7005\n",
            "Epoch [72/100] - Loss: 15.1511\n",
            "Epoch [73/100] - Loss: 11.7918\n",
            "Epoch [74/100] - Loss: 13.0823\n",
            "Epoch [75/100] - Loss: 12.7388\n",
            "Epoch [76/100] - Loss: 12.3413\n",
            "Epoch [77/100] - Loss: 12.2514\n",
            "Epoch [78/100] - Loss: 10.1468\n",
            "Epoch [79/100] - Loss: 12.6066\n",
            "Epoch [80/100] - Loss: 9.2055\n",
            "Epoch [81/100] - Loss: 9.2851\n",
            "Epoch [82/100] - Loss: 9.4814\n",
            "Epoch [83/100] - Loss: 10.4672\n",
            "Epoch [84/100] - Loss: 10.1220\n",
            "Epoch [85/100] - Loss: 10.8894\n",
            "Epoch [86/100] - Loss: 9.7239\n",
            "Epoch [87/100] - Loss: 9.9488\n",
            "Epoch [88/100] - Loss: 9.9067\n",
            "Epoch [89/100] - Loss: 7.7730\n",
            "Epoch [90/100] - Loss: 11.6200\n",
            "Epoch [91/100] - Loss: 11.2343\n",
            "Epoch [92/100] - Loss: 6.9910\n",
            "Epoch [93/100] - Loss: 6.6024\n",
            "Epoch [94/100] - Loss: 12.1847\n",
            "Epoch [95/100] - Loss: 10.8158\n",
            "Epoch [96/100] - Loss: 10.3930\n",
            "Epoch [97/100] - Loss: 9.9758\n",
            "Epoch [98/100] - Loss: 8.3907\n",
            "Epoch [99/100] - Loss: 8.3822\n",
            "Epoch [100/100] - Loss: 8.6983\n"
          ]
        }
      ],
      "source": [
        "# MiniBERTのトレーニング\n",
        "\n",
        "from torch import optim\n",
        "import random\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "# - vocab_size: 語彙のサイズ\n",
        "# - embed_dim: 各トークンの埋め込みの次元数\n",
        "# - num_heads: マルチヘッドセルフアテンションで使用するヘッドの数\n",
        "# - ff_dim: フィードフォワードサブレイヤーの次元数\n",
        "# - num_layers: スタックするエンコーダーブロックの数\n",
        "# - max_len: 最大シーケンス長\n",
        "# 最後にGPUに送る\n",
        "\n",
        "model = MiniBert(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=64,\n",
        "    num_heads=2,\n",
        "    ff_dim=128,\n",
        "    num_layers=2,\n",
        "    max_len=12\n",
        ").to(device)\n",
        "\n",
        "# 最適化関数はAdamを使用\n",
        "# Adamは、各パラメータの学習率を動的に調整するアルゴリズムで、\n",
        "# 勾配の1次モーメントと2次モーメントの推定に基づいている。\n",
        "# ニューラルネットワークのトレーニングにおいて、よく使われるデフォルトの選択肢。\n",
        "# lr=1e-3は、一般的な初期学習率。\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3) # 第一引数：調整するパラメーター\n",
        "\n",
        "# 損失関数はCrossEntropyLossを使用\n",
        "# CrossEntropyLossは、分類問題に使われる損失関数で、\n",
        "# モデルの出力（logits）と正解ラベル（labels）を比較して、モデルの性能を評価\n",
        "# 具体的には、モデルが予測した各トークンの確率分布と、正解のトークンのインデックスを比較\n",
        "# これは、モデルが予測した確率分布が、正解のトークンの分布とどれだけ一致しているかを測定\n",
        "# ignore_index=-100は、-100でラベル付けされた位置は損失計算に影響しないことを意味\n",
        "# これにより、マスクされたトークンの位置に対してのみ損失を計算するために使用\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-100) # 二乗誤差\n",
        "\n",
        "# エポック数\n",
        "# どのくらいの回数データセットを使用して学習するか\n",
        "epochs = 100\n",
        "\n",
        "# バッチサイズ\n",
        "# 1回の学習で処理する文の数\n",
        "batch_size = 64\n",
        "\n",
        "# データセットサイズは文の数\n",
        "# ミニバッチを作成するために取得\n",
        "dataset_size = encoded_datasets.size(0)\n",
        "\n",
        "# trainモードに切り替えることで、ドロップアウトなどのレイヤーがトレーニング時の動作をするようにする。\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    total_loss = 0\n",
        "\n",
        "\t  # データセットのインデックスをシャッフルする\n",
        "    indices = list(range(dataset_size))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "\t  # バッチサイズごとにデータを処理する\n",
        "    for i in range(0, dataset_size, batch_size):\n",
        "\t\t    # シャッフルしたリストからバッチインデックスを取得\n",
        "        batch_idx = indices[i:i+batch_size]\n",
        "\t\t    # encoded_datasetsからバッチインデックスに基づいて行を取得し、GPUに移動\n",
        "        batch = encoded_datasets[batch_idx].to(device)\n",
        "\n",
        "\t\t    # マスクトークンを適用して、[MASK]トークンを含むinput_idsと正解ラベルlabelsを作成\n",
        "        input_ids, labels = mask_tokens(batch)\n",
        "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
        "\n",
        "        # input_idsをモデルに通して、語彙サイズのロジットを得る\n",
        "        # [B, S] -> [B, S, vocab_size]\n",
        "        logits = model(input_ids)\n",
        "\n",
        "        # CrossEntropyLossを使用して損失を計算\n",
        "        # ロジットを[B*S, vocab_size]の形にフラット化し、ラベルを[B*S]の形にする\n",
        "        # これにより、各トークン位置が別々の分類問題として扱われる\n",
        "        loss = criterion(logits.view(-1, vocab_size), labels.view(-1))\n",
        "\n",
        "\n",
        "\t    \t# 逆伝播を行う前に、既存の勾配をゼロにする。（PyTorchはデフォルトで勾配を蓄積するため）\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\t    \t# 逆伝播で勾配を計算する\n",
        "        loss.backward()\n",
        "\n",
        "\t    \t# 勾配を使ってパラメータを更新する\n",
        "        optimizer.step()\n",
        "\n",
        "\t\t    # 損失を累積して、あとでエポック全体の平均を計算する\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\t  # エポック全体の平均損失を計算\n",
        "    avg_loss = total_loss / (dataset_size / batch_size)\n",
        "    print(f\"Epoch [{epoch}/{epochs}] - Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "177a9a8a",
      "metadata": {
        "id": "177a9a8a",
        "outputId": "f115ace5-7d8b-4f36-c6cb-dabed7f537c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: hello how are [MASK] doing today\n",
            "Top predictions for [MASK]:\n",
            "  you (logit: 4.84)\n",
            "  doing (logit: 3.18)\n",
            "  are (logit: 1.84)\n",
            "  a (logit: 0.91)\n",
            "  again (logit: 0.73)\n"
          ]
        }
      ],
      "source": [
        "# 最後に評価\n",
        "\n",
        "# 例えば、\"hello how are [MASK] doing today\"という文を使って、\n",
        "# モデルが\"[MASK]\"を\"you\"と予測できるかを確認する\n",
        "\n",
        "def encode_for_test(sentence, word2idx, max_len=12):\n",
        "  \t# 文の中の句読点を削除する\n",
        "    for p in [\".\", \",\", \"?\", \"!\", \":\", \";\"]:\n",
        "        sentence = sentence.replace(p, \"\")\n",
        "\n",
        "\t# 文をスペースで分割してトークン化する\n",
        "    tokens = sentence.strip().split()\n",
        "\n",
        "\t# [CLS]は文の開始を示し、[SEP]は文の終了を示す\n",
        "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "    token_ids = []\n",
        "\n",
        "\t# それぞれのトークンを整数IDに変換、もしくは語彙にない場合は[UNK]を使用\n",
        "    for t in tokens:\n",
        "        token_ids.append(word2idx.get(t, word2idx[\"[UNK]\"]))\n",
        "\n",
        "\t# もしtoken_idsがmax_lenより短い場合、[PAD]を追加してシーケンスを埋める\n",
        "    if len(token_ids) < max_len:\n",
        "        token_ids += [word2idx[\"[PAD]\"]] * (max_len - len(token_ids))\n",
        "    else:\n",
        "        token_ids = token_ids[:max_len]\n",
        "\n",
        "\t# 2次元のテンソルに変換して、バッチサイズ1としてモデルに渡す\n",
        "    return torch.tensor(token_ids).unsqueeze(0)\n",
        "\n",
        "# [MASK]を含む文を定義\n",
        "test_sentence = \"hello how are [MASK] doing today\"\n",
        "\n",
        "# モデルを評価モードに切り替える。これにより、ドロップアウトや他のトレーニング特有の動作がオフになる。\n",
        "model.eval()\n",
        "\n",
        "# torch.no_grad()は、勾配計算を無効にするためのコンテキストマネージャーで、\n",
        "# モデルの評価時に使用される。これにより、メモリと計算を節約できる。\n",
        "with torch.no_grad():\n",
        "\n",
        "\t  # test sentenceをトークンIDにエンコード\n",
        "    test_ids = encode_for_test(test_sentence, word2idx).to(device)\n",
        "\n",
        "\t  # モデルに入力して、語彙サイズのロジットを得る\n",
        "    logits = model(test_ids)\n",
        "\n",
        "    # [MASK]の位置を見つける\n",
        "    # test_ids[0]は1次元テンソルで、word2idx[\"[MASK]\"]と比較してTrue/Falseを返す\n",
        "    mask_idx = (test_ids[0] == word2idx[\"[MASK]\"]).nonzero(as_tuple=True)\n",
        "\n",
        "\t  # もし[MASK]が1つ以上ある場合\n",
        "    if len(mask_idx[0]) > 0:\n",
        "\n",
        "\t    \t# 最初の[MASK]のインデックスを取得\n",
        "        pos = mask_idx[0].item()\n",
        "\n",
        "\t\t    # logitsは[B, S, vocab_size]の形をしているので、最初のバッチの特定の位置のロジットを取得\n",
        "        mask_logits = logits[0, pos, :]\n",
        "\n",
        "\t\t    # topkで、最も高い5つのロジットを取得\n",
        "        top_values, top_indices = torch.topk(mask_logits, 5)\n",
        "\n",
        "        print(\"Input:\", test_sentence)\n",
        "        print(\"Top predictions for [MASK]:\")\n",
        "\n",
        "\t    \t# トークンIDをトークン文字列にマッピングして、ロジットを表示\n",
        "        for i in range(5):\n",
        "            pred_id = top_indices[i].item()\n",
        "            pred_word = idx2word[pred_id]\n",
        "            print(f\"  {pred_word} (logit: {top_values[i].item():.2f})\")\n",
        "    else:\n",
        "        print(\"No [MASK] found.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}